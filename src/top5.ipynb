{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from pipeline import clean, lemmatizeTot, stemmerTot\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sn\n",
    "import joblib\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(test_labels, pred, multi=False, pos='climate'):\n",
    "    if multi:\n",
    "        average = 'macro'\n",
    "    else:\n",
    "        average = 'binary'\n",
    "    acc = metrics.accuracy_score(test_labels, pred)\n",
    "    recall = metrics.recall_score(test_labels, pred, average=average, pos_label=pos)\n",
    "    precision = metrics.precision_score(test_labels, pred, average=average, pos_label=pos)\n",
    "    f1 = metrics.f1_score(test_labels, pred, average=average, pos_label=pos)\n",
    "    return acc, recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(test_labels, DecScore, pos_label=\"climate\", title=\"ROC curve\"):\n",
    "    print(\"changed\")\n",
    "    fpr, tpr, thres = metrics.roc_curve(test_labels, DecScore, pos_label=pos_label)\n",
    "    auc = metrics.auc(tpr, fpr,)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(tpr, fpr)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return auc\n",
    "\n",
    "def clean(text, do=True):\n",
    "    if (not do):\n",
    "        return text\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    texter = re.sub(r\"<br />\", \" \", text)\n",
    "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
    "    texter = re.sub('\\n', \" \", texter)\n",
    "    texter = re.sub(' u ',\" you \", texter)\n",
    "    texter = re.sub('`',\"\", texter)\n",
    "    texter = re.sub(' +', ' ', texter)\n",
    "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    "    texter = re.sub('&amp;', 'and', texter)\n",
    "    texter = re.sub('\\r', ' ',texter)\n",
    "    texter = re.sub(r'[_]+', ' ', texter)\n",
    "    texter = re.sub(r'[\\d]+', '', texter)\n",
    "    clean = re.compile('<.*?>')\n",
    "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    "    texter = re.sub(clean, '', texter)\n",
    "    if texter == \"\":\n",
    "        texter = \"\"\n",
    "    return texter\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Project1-Classification.csv\")\n",
    "df = df.replace({'%22forest%20fire%22': 'forest fire'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer, SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "vectorizer = TfidfVectorizer(stop_words='english',min_df=5,)\n",
    "lemmaTemp = []\n",
    "df_l = df.copy()\n",
    "df_l['full_text'] = df_l['full_text'].apply(nltk.word_tokenize)\n",
    "for article in df_l[\"full_text\"]:\n",
    "    lemmaTemp.append(' '.join(lemmatizer.lemmatize(word) for word in article))\n",
    "df_l['full_text'] = lemmaTemp\n",
    "df_c = df.copy()\n",
    "df_c['full_text'] = df_c['full_text'].apply(clean)\n",
    "df_cs = df_c.copy()\n",
    "df_cs['full_text'] = df_cs['full_text'].apply(nltk.word_tokenize)\n",
    "stemmerTemp = []\n",
    "for article in df_cs[\"full_text\"]:\n",
    "    stemmerTemp.append(' '.join(stemmer.stem(word)\n",
    "                        for word in article))\n",
    "df_cs['full_text'] = stemmerTemp\n",
    "\n",
    "lemmaTemp = []\n",
    "df_cl = df_c.copy()\n",
    "df_cl['full_text'] = df_cl['full_text'].apply(nltk.word_tokenize)\n",
    "for article in df_cl[\"full_text\"]:\n",
    "    lemmaTemp.append(' '.join(lemmatizer.lemmatize(word) for word in article))\n",
    "df_cl['full_text'] = lemmaTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',min_df=5)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "lsi = TruncatedSVD(random_state=42, n_components=80)\n",
    "logl1 = LogisticRegression(solver='saga', penalty='l1',\n",
    "                              C=10, random_state=42, max_iter=20000)\n",
    "logl2 = LogisticRegression(solver='saga', penalty='l2',\n",
    "                              C=500, random_state=42, max_iter=20000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dirty lemma 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l, test_l = train_test_split(df_l, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_train_l = vectorizer.fit_transform(train_l['full_text'])\n",
    "vect_test_l = vectorizer.transform(test_l['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_train_l = lsi.fit_transform(vect_train_l, train_l['root_label'])\n",
    "red_test_l = lsi.transform(vect_test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logl1.fit(red_train_l, train_l['root_label'])\n",
    "pred_l1 = logl1.predict(red_test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9650793650793651\n",
      "recall: 0.9771863117870723\n",
      "precision: 0.9413919413919414\n",
      "f1: 0.9589552238805971\n"
     ]
    }
   ],
   "source": [
    "acc, recall, precision, f1 = classification_metrics(test_l['root_label'], pred_l1)\n",
    "print(f\"acc: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"f1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9650793650793651\n",
      "recall: 0.9771863117870723\n",
      "precision: 0.9413919413919414\n",
      "f1: 0.9589552238805971\n"
     ]
    }
   ],
   "source": [
    "logl2.fit(red_train_l, train_l['root_label'])\n",
    "pred_l2 = logl2.predict(red_test_l)\n",
    "acc, recall, precision, f1 = classification_metrics(test_l['root_label'], pred_l2)\n",
    "print(f\"acc: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"f1: {f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean stem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cs, test_cs = train_test_split(df_cs, test_size=.2, random_state=42)\n",
    "vect_train_cs = vectorizer.fit_transform(train_cs['full_text'])\n",
    "vect_test_cs = vectorizer.transform(test_cs['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_train_cs = lsi.fit_transform(vect_train_cs, train_cs['root_label'])\n",
    "red_test_cs = lsi.transform(vect_test_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9682539682539683\n",
      "recall: 0.9809885931558935\n",
      "precision: 0.945054945054945\n",
      "f1: 0.962686567164179\n"
     ]
    }
   ],
   "source": [
    "logl1.fit(red_train_cs, train_cs['root_label'])\n",
    "pred_cs1 = logl1.predict(red_test_cs)\n",
    "acc, recall, precision, f1 = classification_metrics(test_cs['root_label'], pred_cs1)\n",
    "print(f\"acc: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"f1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9666666666666667\n",
      "recall: 0.9809885931558935\n",
      "precision: 0.9416058394160584\n",
      "f1: 0.9608938547486034\n"
     ]
    }
   ],
   "source": [
    "logl2.fit(red_train_cs, train_cs['root_label'])\n",
    "pred_cs2 = logl2.predict(red_test_cs)\n",
    "acc, recall, precision, f1 = classification_metrics(test_cs['root_label'], pred_cs2)\n",
    "print(f\"acc: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"f1: {f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaned lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cl, test_cl = train_test_split(df_cl, test_size=.2, random_state=42)\n",
    "vect_train_cl = vectorizer.fit_transform(train_cl['full_text'])\n",
    "vect_test_cl = vectorizer.transform(test_cl['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_train_cl = lsi.fit_transform(vect_train_cl, train_cl['root_label'])\n",
    "red_test_cl = lsi.transform(vect_test_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9682539682539683\n",
      "recall: 0.9809885931558935\n",
      "precision: 0.945054945054945\n",
      "f1: 0.962686567164179\n"
     ]
    }
   ],
   "source": [
    "logl1.fit(red_train_cl, train_cl['root_label'])\n",
    "pred_cl1 = logl1.predict(red_test_cl)\n",
    "acc, recall, precision, f1 = classification_metrics(test_cl['root_label'], pred_cl1)\n",
    "print(f\"acc: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"f1: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dd9799330aa9e07098a1bcddb093d901527862010f5a7bbd47eca5502e7e4da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
